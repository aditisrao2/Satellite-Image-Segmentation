# Satellite-Image-Segmentation
Aerial imagery segmentation is essential in geospatial analysis, enabling pixel classification into categories like infrastructure, vegetation, water bodies, and open land. This detailed mapping is crucial for high-accuracy tasks in environmental conservation, urban growth analysis, and disaster response. 

Recent advancements in deep learning, particularly with models like U-Net and DeepLabV3+, have significantly enhanced the accuracy of these classifications.  U-Netâ€™s encoder-decoder structure captures spatial details for fine-grained segmentation, while DeepLabV3+ enhances contextual understanding through atrous convolutions and spatial pyramid pooling. This project aims to utilize both architectures for accurate segmentation of aerial imagery.

For post-hurricane damage assessment, an initial exploratory analysis of the dataset was conducted, followed by the implementation of a CNN model to identify structural damage, debris, and other disaster indicators. This approach allows for swift and precise evaluations of affected areas. 

Ultimately the project enhances landscape analysis, supporting better decision making in environmental sustainability, infrastructure planning, and disaster management. By generating quick damage assessment maps from a single aerial flyover, the model offers vital insights for post-disaster recovery, enabling agencies to rapidly assess impacts and allocate resources effectively.

## Standard U-NET
U-Net stands out as a prominent architecture for image segmentation, introduced in 2015 as a groundbreaking advancement in the processing of biomedical images, and developed from the principles of traditional convolutional neural networks. This innovative architecture is distinguished by its unique U-shaped configuration, which incorporates an encoder-decoder framework. The encoder adeptly captures intricate image features through successive convolutions and down-sampling, while the decoder meticulously reconstructs these features, up-sampling them back to the original input dimensions. This process allows for the accurate localization and classification of each pixel into designated semantic categories. The U shape is a defining characteristic, formed by the connections between convolutional blocks at the base of the network, which not only facilitates a seamless transition from feature extraction to reconstruction but also enhances the model's ability to preserve vital spatial information throughout the segmentation journey.

## DEEPLAB V3+ 
DeepLabv3+ is the latest advancement in the esteemed DeepLab series of deep learning architectures for semantic image segmentation, originally open-sourced by Google Inc. in 2016. This architecture retains the encoder-decoder framework while introducing the innovative Atrous Spatial Pyramid Pooling (ASPP) strategy. ASPP applies parallel dilated convolutions at various rates to the input feature map, enabling the model to seamlessly integrate features across multiple scales, which is essential for accurately segmenting objects of differing sizes within a single image. Furthermore, DeepLabv3+ employs Dilated Convolutions, which enhance conventional convolutions by inserting gaps within the kernel elements, dictated by a parameter known as the dilation rate. This unique approach allows for a wider coverage of the input image without the need for pooling, thereby enriching the model's ability to gather comprehensive contextual information with each convolutional operation.
